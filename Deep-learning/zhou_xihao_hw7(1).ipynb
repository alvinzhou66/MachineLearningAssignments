{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: LSTM on txt data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. concatenate all txt files into one corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Book Files/books/'\n",
    "names = ['MLOE.txt','TPP.txt','OKEWFSMP.txt','TAM.txt','TAMatter.txt','THWP.txt']\n",
    "output = open('corpus.txt', 'w')\n",
    "\n",
    "for i in range(len(names)):\n",
    "    file = path+names[i]\n",
    "    with open(file, encoding='ascii', errors='ignore') as book:\n",
    "        for line in book:\n",
    "            output.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. encode the characters in that file into range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = open('corpus.txt').read().lower()\n",
    "chars = []\n",
    "for n in row_data:\n",
    "    chars.extend(list(set(set(n))))\n",
    "chars = sorted(list(set(chars)))\n",
    "chars_dict = dict((c, i) for i, c in enumerate(chars))\n",
    "char_amount = len(row_data)\n",
    "word_amount = len(chars)\n",
    "int_dict = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. set window size = 100 and make every first 99 in a window as input, output the 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat x as input and y as output\n",
    "x=[]\n",
    "y=[]\n",
    "window_select = np.arange(0, char_amount-100, 1)\n",
    "for i in window_select:\n",
    "    input_range = row_data[i:i+100]\n",
    "    output_word = row_data[i+100]\n",
    "    y.append(chars_dict[output_word])\n",
    "    temp=[]\n",
    "    for k in input_range:\n",
    "        temp.append(chars_dict[k]/float(word_amount))\n",
    "    x.append(temp)\n",
    "chunk_amout=len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. convert y from int type into catigorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y)\n",
    "x = np.reshape(x, (chunk_amout, 100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. single layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               264192    \n",
      "=================================================================\n",
      "Total params: 264,192\n",
      "Trainable params: 264,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2])))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. softmax output layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 67)                17219     \n",
      "=================================================================\n",
      "Total params: 281,411\n",
      "Trainable params: 281,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. select resonable epochs and test checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4346517/4346517 [==============================] - 894s 206us/step - loss: 2.6757\n",
      "Epoch 2/30\n",
      "4346517/4346517 [==============================] - 889s 204us/step - loss: 2.5553\n",
      "Epoch 3/30\n",
      "4346517/4346517 [==============================] - 886s 204us/step - loss: 2.3668\n",
      "Epoch 4/30\n",
      "4346517/4346517 [==============================] - 875s 201us/step - loss: 2.1658\n",
      "Epoch 5/30\n",
      "4346517/4346517 [==============================] - 879s 202us/step - loss: 2.0501\n",
      "Epoch 6/30\n",
      "4346517/4346517 [==============================] - 873s 201us/step - loss: 1.9735\n",
      "Epoch 7/30\n",
      "4346517/4346517 [==============================] - 874s 201us/step - loss: 1.9176\n",
      "Epoch 8/30\n",
      "4346517/4346517 [==============================] - 871s 200us/step - loss: 1.8748\n",
      "Epoch 9/30\n",
      "4346517/4346517 [==============================] - 873s 201us/step - loss: 1.8404\n",
      "Epoch 10/30\n",
      "4346517/4346517 [==============================] - 876s 202us/step - loss: 1.8118\n",
      "Epoch 11/30\n",
      "4346517/4346517 [==============================] - 878s 202us/step - loss: 1.7824\n",
      "Epoch 12/30\n",
      "4346517/4346517 [==============================] - 880s 202us/step - loss: 1.7587\n",
      "Epoch 13/30\n",
      "4346517/4346517 [==============================] - 883s 203us/step - loss: 1.7393\n",
      "Epoch 14/30\n",
      "4346517/4346517 [==============================] - 878s 202us/step - loss: 1.7230\n",
      "Epoch 15/30\n",
      "4346517/4346517 [==============================] - 882s 203us/step - loss: 1.7081\n",
      "Epoch 16/30\n",
      "4346517/4346517 [==============================] - 880s 202us/step - loss: 1.6947\n",
      "Epoch 17/30\n",
      "4346517/4346517 [==============================] - 881s 203us/step - loss: 1.9363\n",
      "Epoch 18/30\n",
      "4346517/4346517 [==============================] - 877s 202us/step - loss: 2.3863\n",
      "Epoch 19/30\n",
      "4346517/4346517 [==============================] - 875s 201us/step - loss: 2.0641\n",
      "Epoch 20/30\n",
      "4346517/4346517 [==============================] - 877s 202us/step - loss: 1.7327\n",
      "Epoch 21/30\n",
      "4346517/4346517 [==============================] - 879s 202us/step - loss: 1.6827\n",
      "Epoch 22/30\n",
      "4346517/4346517 [==============================] - 879s 202us/step - loss: 1.7179\n",
      "Epoch 23/30\n",
      "4346517/4346517 [==============================] - 880s 202us/step - loss: 2.5740\n",
      "Epoch 24/30\n",
      "4346517/4346517 [==============================] - 899s 207us/step - loss: 2.4950\n",
      "Epoch 25/30\n",
      "4346517/4346517 [==============================] - 908s 209us/step - loss: 2.3345\n",
      "Epoch 26/30\n",
      "4346517/4346517 [==============================] - 900s 207us/step - loss: 2.2090\n",
      "Epoch 27/30\n",
      "4346517/4346517 [==============================] - 910s 209us/step - loss: 2.1119\n",
      "Epoch 28/30\n",
      "4346517/4346517 [==============================] - 908s 209us/step - loss: 2.0389\n",
      "Epoch 29/30\n",
      "4346517/4346517 [==============================] - 913s 210us/step - loss: 1.9854\n",
      "Epoch 30/30\n",
      "4346517/4346517 [==============================] - 906s 208us/step - loss: 1.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f75e028cf98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using code from official documents: https://keras.io/zh/callbacks/#modelcheckpoint\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "checkpointer = ModelCheckpoint(filepath='LSTMcheckpoints/weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', mode='min', verbose=0, save_best_only=True)\n",
    "model.fit(x, y, batch_size=512, epochs=30, verbose=1, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. use the best loss weights, try to write like the author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(x.shape[1],x.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.load_weights(\"LSTMcheckpoints/weights.21-1.68.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "initial = initial.lower()\n",
    "chars = []\n",
    "for n in initial:\n",
    "    chars.append(chars_dict[n])\n",
    "chars = chars[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "\n",
      "the same tame the soarat of the point of view of the particular \n",
      "aetirativ that is the same tienry of shahet that the semsa oa \n",
      "she soace of the part of the part of the part of the poentsion \n",
      "of the point of view. and the soarates of the part of the \n",
      "semsa in which the semse of the part of the point of view of \n",
      "the part of the particular than the soace of the particular \n",
      "aetiraty of the particular enemgsh. the semoe of the semse of \n",
      "the eoem oo the part of the point of view that the semsa oa \n",
      "she soace of the part of the part of the part of the \n",
      "perception of the particular enemgsh. \n",
      "\n",
      "the semse of the part of the point of view of the semse of \n",
      "the part of the poentsion of the part of the point of view. \n",
      "\n",
      "the content of the part of the eoel oo the part of the point of view. the semoe of the \n",
      "consedot lenser of the part of the point of view of the particular enemgsh. the semoe of the \n",
      "consedot lenser the same aog to cemtarn the soace of the \n",
      "perception of the part of the poentsion of "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    x = np.reshape(chars, (1, len(chars), 1))\n",
    "    x = x / float(word_amount)\n",
    "    # get the predicted int value\n",
    "    pred = model.predict(x, verbose=0)\n",
    "    index = np.argmax(pred)\n",
    "    # convert int to char\n",
    "    result = int_dict[index]\n",
    "    sys.stdout.write(result)\n",
    "\n",
    "    # move window, drop the first and add the predict one\n",
    "    chars.append(index)\n",
    "    chars = chars[1:len(chars)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
